{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9xV5aniYW6Z"
      },
      "outputs": [],
      "source": [
        "# Python\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# NumPy and PyTorch\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Custom\n",
        "from path_reader import PathDataLoader\n",
        "from networks import SiameseNetwork\n",
        "from losses import ContrastiveLossSimple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-eM4BLfZ3ZE"
      },
      "outputs": [],
      "source": [
        "def init_data(paths, batch_size, ratio):\n",
        "\n",
        "    all_data = []\n",
        "    all_hash = []\n",
        "\n",
        "    for i in range(len(paths)):\n",
        "      for j in range(len(paths[0])):\n",
        "        if len(paths[i][j]) != 0:\n",
        "          for k in paths[i][j]:\n",
        "            arr = []\n",
        "            c = 0\n",
        "            for l in range(len(k.points)):\n",
        "              c += 1\n",
        "              for m in range(len(k.points[l])):\n",
        "                arr.append(k.points[l][m])\n",
        "            for l in range((5-c)*3, 0, -1):\n",
        "              arr.append(0)\n",
        "            for l in range(len(k.interaction_types)):\n",
        "              arr.append(k.interaction_types[l])\n",
        "            for l in range(5-c, 0, -1):\n",
        "              arr.append(0)\n",
        "            all_hash.append(k.hash)\n",
        "            arr.append(k.path_gain_db)\n",
        "            all_data.append(arr)\n",
        "\n",
        "    data_pairs = []\n",
        "    tol = 1000000\n",
        "    for i in range(len(all_data)):\n",
        "        for j in range(len(all_data)):\n",
        "            if i != j:  # Ensure the pairs are not identical\n",
        "                if abs(all_hash[i] - all_hash[j]) < tol:\n",
        "                  label = 0\n",
        "                else:\n",
        "                  label = 1\n",
        "                data_pairs.append((torch.tensor(all_data[i], dtype=torch.float), torch.tensor(all_data[j], dtype=torch.float), torch.tensor(label, dtype=torch.long)))\n",
        "        print(len(data_pairs))\n",
        "        if len(data_pairs) > 1000000:\n",
        "          break\n",
        "\n",
        "    dataloaders = DataLoader(data_pairs, batch_size, shuffle=True)\n",
        "    \"\"\"\n",
        "    numpy_data = np.array(data_pairs)\n",
        "\n",
        "    datasets = {}\n",
        "    datasets['train'] = np.array(numpy_data[:int(len(numpy_data) * ratio)])\n",
        "    datasets['val'] = np.array(numpy_data[int(len(numpy_data) * ratio):])\n",
        "\n",
        "\n",
        "    # Shuffle data\n",
        "    dataset_length = len(datasets['train'])\n",
        "    indices = list(range(dataset_length))\n",
        "    np.random.shuffle(indices)\n",
        "    sampler = torch.utils.data.SubsetRandomSampler(indices)\n",
        "\n",
        "    # Create DataLoaders using these samplers\n",
        "    dataloaders = {\n",
        "        'train': torch.utils.data.DataLoader(\n",
        "            datasets['train'],\n",
        "            batch_size=batch_size,\n",
        "            sampler=sampler,\n",
        "            num_workers=2,\n",
        "            pin_memory=False,\n",
        "        ),\n",
        "        'val': torch.utils.data.DataLoader(\n",
        "            datasets['val'],\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2,\n",
        "            pin_memory=False,\n",
        "        )\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    return dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRDoWV3cZe8O"
      },
      "outputs": [],
      "source": [
        "def train_siamese_network(train_loader, net, criterion, optimizer, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            input1, input2, label = data\n",
        "            output1, output2 = net(input1), net(input2)\n",
        "            loss = criterion(output1, output2, label)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if i % 1000 == 0:\n",
        "                print(f\"Epoch {epoch}, Iteration {i}, Loss {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAR6yRplYVun"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "pathLoader = PathDataLoader()\n",
        "paths = pathLoader.read_file('eu_city_2x2_macro_306.bin')\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWKH4t4_Z_fg",
        "outputId": "47d6100d-fc84-4944-c4f1-e6f8459760a9"
      },
      "outputs": [],
      "source": [
        "# Format data\n",
        "batch_size = 10\n",
        "train_val_ratio = 0.95\n",
        "dataloaders = init_data(paths, batch_size, train_val_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpjGuBhwYDfc"
      },
      "outputs": [],
      "source": [
        "# Instantiate the Siamese Network and Loss Function\n",
        "net = SiameseNetwork()\n",
        "criterion = ContrastiveLossSimple()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHM22PM6acnD",
        "outputId": "30a2f770-f761-4db7-d679-93e118c47645"
      },
      "outputs": [],
      "source": [
        "train_siamese_network(dataloaders, net, criterion, optimizer, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qG3d3BrkBYvs"
      },
      "outputs": [],
      "source": [
        "all_data = []\n",
        "all_hash = []\n",
        "for i in range(len(paths)):\n",
        "  for j in range(len(paths[0])):\n",
        "    if len(paths[i][j]) != 0:\n",
        "      for k in paths[i][j]:\n",
        "        arr = []\n",
        "        c = 0\n",
        "        for l in range(len(k.points)):\n",
        "          c += 1\n",
        "          for m in range(len(k.points[l])):\n",
        "            arr.append(k.points[l][m])\n",
        "        for l in range((5-c)*3, 0, -1):\n",
        "          arr.append(0)\n",
        "        for l in range(len(k.interaction_types)):\n",
        "          arr.append(k.interaction_types[l])\n",
        "        for l in range(5-c, 0, -1):\n",
        "          arr.append(0)\n",
        "        arr.append(k.path_gain_db)\n",
        "        all_hash.append(k.hash)\n",
        "        all_data.append(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imPHFZCX9-Cr",
        "outputId": "c66ebfc1-e6bf-44af-e3c0-8348f912e007"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "hash1 = all_hash[index1]\n",
        "hash2 = all_hash[index2]\n",
        "\n",
        "for i in range(len(all_hash)):\n",
        "  for j in range(len(all_hash)):\n",
        "    if i != j and all_hash[i] < 3000000000 and all_hash[j] < 3000000000:\n",
        "      if abs(all_hash[i] - all_hash[j]) < 750000000:\n",
        "        print(\"i\", i)\n",
        "        print(\"hash i\", all_hash[i])\n",
        "        print(\"j\", j)\n",
        "        print(\"hash j\", all_hash[j])\n",
        "\"\"\"\n",
        "\n",
        "print(all_hash[0])\n",
        "print(all_hash[1])\n",
        "index1 = 0\n",
        "index2 = 1\n",
        "print(torch.tensor(all_data[index1]))\n",
        "print(torch.tensor(all_data[index2]))\n",
        "print(net(torch.tensor(all_data[index1])))\n",
        "print(net(torch.tensor(all_data[index2])))\n",
        "embeddings = net(torch.tensor(all_data[index2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "mRuG3fKUCHcN",
        "outputId": "314bbfae-86bf-47d1-eda2-2e836a41411d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have the 1D embeddings stored in the 'embeddings' variable\n",
        "\n",
        "# Convert embeddings to a list\n",
        "embeddings_list = embeddings.squeeze().tolist()\n",
        "\n",
        "# Create x-axis indices\n",
        "indices = list(range(len(embeddings_list)))\n",
        "\n",
        "# Plot the 1D embeddings\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(indices, embeddings_list, marker='o', linestyle='-')\n",
        "plt.title('Visualization of 1D Embeddings')\n",
        "plt.xlabel('Component')\n",
        "plt.ylabel('Embedding Value')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
