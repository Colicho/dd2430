{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9xV5aniYW6Z"
      },
      "outputs": [],
      "source": [
        "# Supress warnings\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "\n",
        "# Python\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# NumPy and PyTorch\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Custom\n",
        "from path_loader import PathDataLoader\n",
        "from networks import SiameseNetworkSimple\n",
        "from losses import ContrastiveLossSimple\n",
        "from patch_generator import PatchGenerator\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-eM4BLfZ3ZE"
      },
      "outputs": [],
      "source": [
        "def init_data(paths, batch_size, ratio):\n",
        "\n",
        "    all_data = []\n",
        "    all_hash = []\n",
        "\n",
        "    for i in range(len(paths)):\n",
        "      for j in range(len(paths[0])):\n",
        "        if len(paths[i][j]) != 0:\n",
        "          for k in paths[i][j]:\n",
        "            arr = []\n",
        "            c = 0\n",
        "            for l in range(len(k.points)):\n",
        "              c += 1\n",
        "              for m in range(len(k.points[l])):\n",
        "                arr.append(k.points[l][m])\n",
        "            for l in range((5-c)*3, 0, -1):\n",
        "              arr.append(0)\n",
        "            for l in range(len(k.interaction_types)):\n",
        "              arr.append(k.interaction_types[l])\n",
        "            for l in range(5-c, 0, -1):\n",
        "              arr.append(0)\n",
        "            all_hash.append(k.hash)\n",
        "            arr.append(k.path_gain_db)\n",
        "            min_val = min(arr)\n",
        "            max_val = max(arr)\n",
        "\n",
        "            # Normalize the list to the range -1 to 1\n",
        "            normalized_data = [2 * (x - min_val) / (max_val - min_val) - 1 for x in arr]\n",
        "            all_data.append(normalized_data)\n",
        "\n",
        "    data_pairs = []\n",
        "    tol = 1200000\n",
        "    for i in range(len(all_data)):\n",
        "        for j in range(len(all_data)):\n",
        "            if i != j:  # Ensure the pairs are not identical\n",
        "                if abs(all_hash[i] - all_hash[j]) < tol:\n",
        "                  label = 0\n",
        "                else:\n",
        "                  label = 1\n",
        "                data_pairs.append((torch.tensor(all_data[i], dtype=torch.float), torch.tensor(all_data[j], dtype=torch.float), torch.tensor(label, dtype=torch.long)))\n",
        "        print(len(data_pairs))\n",
        "        if len(data_pairs) > 100000:\n",
        "          break\n",
        "\n",
        "    dataloaders = DataLoader(data_pairs, batch_size, shuffle=True, drop_last=True)\n",
        "    \"\"\"\n",
        "    numpy_data = np.array(data_pairs)\n",
        "\n",
        "    datasets = {}\n",
        "    datasets['train'] = np.array(numpy_data[:int(len(numpy_data) * ratio)])\n",
        "    datasets['val'] = np.array(numpy_data[int(len(numpy_data) * ratio):])\n",
        "\n",
        "\n",
        "    # Shuffle data\n",
        "    dataset_length = len(datasets['train'])\n",
        "    indices = list(range(dataset_length))\n",
        "    np.random.shuffle(indices)\n",
        "    sampler = torch.utils.data.SubsetRandomSampler(indices)\n",
        "\n",
        "    # Create DataLoaders using these samplers\n",
        "    dataloaders = {\n",
        "        'train': torch.utils.data.DataLoader(\n",
        "            datasets['train'],\n",
        "            batch_size=batch_size,\n",
        "            sampler=sampler,\n",
        "            num_workers=2,\n",
        "            pin_memory=False,\n",
        "        ),\n",
        "        'val': torch.utils.data.DataLoader(\n",
        "            datasets['val'],\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2,\n",
        "            pin_memory=False,\n",
        "        )\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    return dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRDoWV3cZe8O"
      },
      "outputs": [],
      "source": [
        "def train_siamese_network(train_loader, net, criterion, optimizer, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            input1, input2, label = data\n",
        "            output1, output2 = net(input1), net(input2)\n",
        "            loss = criterion(output1, output2, label)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if i % 1000 == 0:\n",
        "                print(f\"Epoch {epoch}, Iteration {i}, Loss {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transform_patches(patches):\n",
        "    for i in range(len(patches)):\n",
        "        for j in range(len(patches[i])):\n",
        "            path = patches[i][j]\n",
        "            arr = []\n",
        "            c = 0\n",
        "            for l in range(len(path.points)):\n",
        "                c += 1\n",
        "                for m in range(len(path.points[l])):\n",
        "                    arr.append(path.points[l][m])\n",
        "            for l in range((5-c)*3, 0, -1):\n",
        "                arr.append(0)\n",
        "            for l in range(len(path.interaction_types)):\n",
        "                arr.append(path.interaction_types[l])\n",
        "            for l in range(5-c, 0, -1):\n",
        "                arr.append(0)\n",
        "            arr.append(path.path_gain_db)\n",
        "            min_val = min(arr)\n",
        "            max_val = max(arr)\n",
        "\n",
        "            # Normalize the list to the range -1 to 1\n",
        "            normalized_data = [2 * (x - min_val) / (max_val - min_val) - 1 for x in arr]\n",
        "\n",
        "            # Update list\n",
        "            patches[i][j] = normalized_data\n",
        "            \n",
        "    return patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JAR6yRplYVun"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "pathLoader = PathDataLoader()\n",
        "paths = pathLoader.read('eu_city_2x2_macro_306.bin')[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate patches\n",
        "gen = PatchGenerator(num_patches=8, attribute=\"transmitter\")\n",
        "patches = gen.generate_patches(paths)\n",
        "\n",
        "# Transform PathPropagation objects to normalized feature vectors\n",
        "patches = gen.transform_patches(patches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWKH4t4_Z_fg",
        "outputId": "47d6100d-fc84-4944-c4f1-e6f8459760a9"
      },
      "outputs": [],
      "source": [
        "# Format data\n",
        "batch_size = 10\n",
        "train_val_ratio = 0.95\n",
        "dataloaders = init_data(paths, batch_size, train_val_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpjGuBhwYDfc"
      },
      "outputs": [],
      "source": [
        "# Instantiate the Siamese Network and Loss Function\n",
        "net = SiameseNetworkSimple()\n",
        "criterion = ContrastiveLossSimple()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHM22PM6acnD",
        "outputId": "30a2f770-f761-4db7-d679-93e118c47645"
      },
      "outputs": [],
      "source": [
        "train_siamese_network(dataloaders, net, criterion, optimizer, epochs=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "mRuG3fKUCHcN",
        "outputId": "314bbfae-86bf-47d1-eda2-2e836a41411d"
      },
      "outputs": [],
      "source": [
        "# Convert embeddings to a list\n",
        "embeddings_list = embeddings.squeeze().tolist()\n",
        "embeddings_list2 = embeddings2.squeeze().tolist()\n",
        "print(embeddings_list)\n",
        "\n",
        "# Create x-axis indices\n",
        "indices = list(range(len(embeddings_list)))\n",
        "\n",
        "# Plot the 1D embeddings\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(indices, embeddings_list, marker='o', linestyle='-')\n",
        "plt.title('Visualization of 1D Embeddings')\n",
        "plt.xlabel('Component')\n",
        "plt.ylabel('Embedding Value')\n",
        "plt.show()\n",
        "\n",
        "# Plot the 1D embeddings\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(indices, embeddings_list2, marker='o', linestyle='-')\n",
        "plt.title('Visualization of 1D Embeddings')\n",
        "plt.xlabel('Component')\n",
        "plt.ylabel('Embedding Value')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
